{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from keras.datasets import mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#obter os dados e já dividi-los em treinamento e teste automaticamente\n",
    "(X_treinamento, y_treinamento), (X_teste, y_teste) = mnist.load_data() \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, '0')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(X_treinamento[21], cmap='gray')\n",
    "plt.title(y_treinamento[21])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forma:  (60000, 28, 28)\n",
      "Qtd linhas:  60000\n",
      "Qtd colunas:  (28, 28)\n"
     ]
    }
   ],
   "source": [
    "#Mudar dimensão para 784 (original está em 28x28)\n",
    "print(\"Forma: \", X_treinamento.shape)\n",
    "print(\"Qtd linhas: \", len(X_treinamento))\n",
    "print(\"Qtd colunas: \", X_treinamento.shape[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_treinamento = X_treinamento.reshape((len(X_treinamento), np.prod(X_treinamento.shape[1:])))\n",
    "#X_treinamento.shape[1:] → Pega todas as dimensões depois da primeira. No caso (60000, 28, 28), isso retorna (28, 28).\n",
    "#np.prod((28, 28)) → Multiplica 28 × 28 = 784. Isso significa que cada imagem de 28×28 será achatada em um vetor de 784 elementos.\n",
    "#reshape → Isso transforma cada imagem 28×28 em um vetor unidimensional de 784 valores (achatando os dados), mantendo o mesmo número de amostras (60000).\n",
    "\n",
    "#Observação: Se estivéssemos lidando com imagens coloridas (RGB 28×28×3), o código adaptaria automaticamente para 28×28×3 = 2352 entradas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forma:  (10000, 28, 28)\n",
      "Qtd linhas:  10000\n",
      "Qtd colunas:  (28, 28)\n"
     ]
    }
   ],
   "source": [
    "print(\"Forma: \", X_teste.shape)\n",
    "print(\"Qtd linhas: \", len(X_teste))\n",
    "print(\"Qtd colunas: \", X_teste.shape[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,  84, 185, 159, 151,  60,  36,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0, 222, 254, 254, 254,\n",
       "       254, 241, 198, 198, 198, 198, 198, 198, 198, 198, 170,  52,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  67, 114,\n",
       "        72, 114, 163, 227, 254, 225, 254, 254, 254, 250, 229, 254, 254,\n",
       "       140,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,  17,  66,  14,  67,  67,  67,  59,  21,\n",
       "       236, 254, 106,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,  83, 253, 209,  18,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,  22, 233, 255,  83,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0, 129, 254, 238,  44,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,  59, 249, 254,  62,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0, 133, 254, 187,   5,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   9, 205, 248,  58,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 126, 254, 182,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  75, 251,\n",
       "       240,  57,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  19,\n",
       "       221, 254, 166,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         3, 203, 254, 219,  35,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,  38, 254, 254,  77,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,  31, 224, 254, 115,   1,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0, 133, 254, 254,  52,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,  61, 242, 254, 254,  52,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0, 121, 254, 254, 219,  40,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 121, 254, 207,\n",
       "        18,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0], dtype=uint8)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_teste = X_teste.reshape((len(X_teste), np.prod(X_teste.shape[1:])))\n",
    "#Faz a mesma coisa com a base acima, porém com a partição de teste\n",
    "X_teste[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,  84., 185., 159., 151.,  60.,  36.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0., 222.,\n",
       "       254., 254., 254., 254., 241., 198., 198., 198., 198., 198., 198.,\n",
       "       198., 198., 170.,  52.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,  67., 114.,  72., 114., 163., 227.,\n",
       "       254., 225., 254., 254., 254., 250., 229., 254., 254., 140.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,  17.,  66.,  14.,  67.,  67.,  67.,\n",
       "        59.,  21., 236., 254., 106.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,  83., 253., 209.,  18.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,  22., 233., 255.,  83.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0., 129., 254., 238.,  44.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,  59., 249., 254.,  62.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0., 133., 254., 187.,   5.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   9., 205., 248.,  58.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0., 126., 254., 182.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,  75., 251., 240.,  57.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,  19., 221., 254., 166.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         3., 203., 254., 219.,  35.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,  38., 254., 254.,  77.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "        31., 224., 254., 115.,   1.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0., 133., 254., 254.,  52.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "        61., 242., 254., 254.,  52.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0., 121., 254., 254., 219.,  40.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0., 121., 254., 207.,  18.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.], dtype=float32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Fazer a normalização dos dados para float para normalizar os valores entre 0 e 1\n",
    "X_treinamento = X_treinamento.astype('float32')\n",
    "X_teste = X_teste.astype('float32')\n",
    "\n",
    "X_teste[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.32941177, 0.7254902 , 0.62352943,\n",
       "       0.5921569 , 0.23529412, 0.14117648, 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.87058824, 0.99607843, 0.99607843, 0.99607843, 0.99607843,\n",
       "       0.94509804, 0.7764706 , 0.7764706 , 0.7764706 , 0.7764706 ,\n",
       "       0.7764706 , 0.7764706 , 0.7764706 , 0.7764706 , 0.6666667 ,\n",
       "       0.20392157, 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.2627451 , 0.44705883,\n",
       "       0.28235295, 0.44705883, 0.6392157 , 0.8901961 , 0.99607843,\n",
       "       0.88235295, 0.99607843, 0.99607843, 0.99607843, 0.98039216,\n",
       "       0.8980392 , 0.99607843, 0.99607843, 0.54901963, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.06666667, 0.25882354, 0.05490196, 0.2627451 ,\n",
       "       0.2627451 , 0.2627451 , 0.23137255, 0.08235294, 0.9254902 ,\n",
       "       0.99607843, 0.41568628, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.3254902 , 0.99215686, 0.81960785, 0.07058824,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.08627451, 0.9137255 ,\n",
       "       1.        , 0.3254902 , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.5058824 , 0.99607843, 0.93333334, 0.17254902,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.23137255, 0.9764706 ,\n",
       "       0.99607843, 0.24313726, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.52156866, 0.99607843, 0.73333335, 0.01960784,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.03529412, 0.8039216 ,\n",
       "       0.972549  , 0.22745098, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.49411765, 0.99607843, 0.7137255 , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.29411766, 0.9843137 ,\n",
       "       0.9411765 , 0.22352941, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.07450981, 0.8666667 , 0.99607843, 0.6509804 , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.01176471, 0.79607844, 0.99607843,\n",
       "       0.85882354, 0.13725491, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.14901961, 0.99607843, 0.99607843, 0.3019608 , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.12156863, 0.8784314 , 0.99607843,\n",
       "       0.4509804 , 0.00392157, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.52156866, 0.99607843, 0.99607843, 0.20392157, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.23921569, 0.9490196 , 0.99607843,\n",
       "       0.99607843, 0.20392157, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.4745098 , 0.99607843, 0.99607843, 0.85882354, 0.15686275,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.4745098 , 0.99607843,\n",
       "       0.8117647 , 0.07058824, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        ], dtype=float32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Normalizar os dados (255 é o valor máximo de um pixel)\n",
    "\n",
    "X_treinamento /= 255  #Divide por 255 para normalizar os valores entre 0 e 1\n",
    "X_teste /= 255  #Divide por 255 para normalizar os valores entre 0 e 1\n",
    "\n",
    "X_teste[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 1., 0., 0.])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Transformar as 10 classes para dummies variables:\n",
    "y_treinamento = to_categorical(y_treinamento, 10)\n",
    "y_teste = to_categorical(y_teste, 10)\n",
    "\n",
    "y_teste[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Utente\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "#Estrutura da rede neural: 784 → 64 → 64 → 64 → 10\n",
    "#DropOut é utilizado para zerar o um percentual de neurônios para evitar overfitting\n",
    "modelo = Sequential()\n",
    "modelo.add(Dense(units = 64, activation = 'relu', input_dim = 784))\n",
    "modelo.add(Dropout(0.2))\n",
    "modelo.add(Dense(units = 64, activation = 'relu'))\n",
    "modelo.add(Dropout(0.2))\n",
    "modelo.add(Dense(units = 64, activation = 'relu'))\n",
    "modelo.add(Dropout(0.2))\n",
    "modelo.add(Dense(units = 10, activation = 'softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">50,240</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,160</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,160</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">650</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │        \u001b[38;5;34m50,240\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m4,160\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m4,160\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │           \u001b[38;5;34m650\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">59,210</span> (231.29 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m59,210\u001b[0m (231.29 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">59,210</span> (231.29 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m59,210\u001b[0m (231.29 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "modelo.summary()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
